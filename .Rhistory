library(tidyverse)
?diamonds
view(diamonds)
diamonds %>%
ggplot() +
geom_bar(mapping=aes(x=cut))
diamonds %>%
count(cut)
ggplot(data=diamonds) +
geom_histogram(mapping=aes(x=carat),binwidth=0.5)
diamonds %>%
count(cut_width,carat=0.5)
smaller <- diamonds %>%
filter(carat < 3)
ggplot(data=diamonds) +
geom_histogram(mapping=aes(x=carat),binwidth=0.5)
smaller <- diamonds %>%
filter(carat < 3)
smaller <- diamonds %>%
filter(carat < 3)
ggplot(data=smaller) +
geom_histogram(mapping=aes(x=carat),binwidth=0.1)
diamonds %>%
filter(carat < 3) %>%
ggplot(mapping = aes(x=carat)) +
geom_histogram(binwidth=0.1)
diamonds %>%
filter(carat < 3) %>%
ggplot(mapping = aes(x=carat)) +
geom_histogram(binwidth=0.1) +
geom_density(color="blue")
ggplot(data = smaller, mapping = aes(x = carat, colour = cut)) +
geom_freqpoly(binwidth = 0.1)
kaggle competitions download -c hhp
install.packages(kaggle competitions download -c hhp)
install.packages(HHP)
install.packages(HeritageHealthPrize)
library(readxl)
U_S_State_Life_Expectancy_by_Sex_2020 <- read_excel("C:/Users/mcdaw/Downloads/U.S._State_Life_Expectancy_by_Sex__2020.csv")
library(readxl)
U_S_State_Life_Expectancy_by_Sex_2020 <- read_excel("C:/Users/mcdaw/Downloads/U.S._State_Life_Expectancy_by_Sex__2020.xlsx")
View(U_S_State_Life_Expectancy_by_Sex_2020)
Data(state)
View(smaller)
View(U_S_State_Life_Expectancy_by_Sex_2020)
View(smaller)
library(tidyverse)
View(U_S_State_Life_Expectancy_by_Sex_2020)
library(readxl)
USALIFE <- read_excel("C:/Users/mcdaw/Downloads/USALIFE.xlsx")
View(USALIFE)
ggplot(data=USALIFE) +
geom_bar(mapping=aes(x=state))
ggplot(data=USALIFE) +
geom_bar(mapping=aes(x=State))
ggplot(data=USALIFE) +
geom_histogram(mapping=aes(x=State))
ggplot(data=USALIFE) +
geom_histogram(mapping=aes(x=SE))
ggplot(data = USALIFE) +
geom_point(mapping = aes(x = Sex, y = LE))
ggplot(data = USALIFE) +
geom_smooth(mapping = aes(x = Sex, y = LE))
ggplot(data = USALIFE) +
geom_bar(mapping = aes(x = Sex))
ggplot(data=gapminder) +
geom_histogram(mapping=aes(x=lifeExp))
ggplot(data = USALIFE, mapping = aes(x = State, colour = Sex)) +
geom_freqpoly(binwidth = 0.1)
ggplot(data = USALIFE, mapping = aes(x = State, colour = Sex)) +
geom_freqpoly(binwidth = 0.1)
ggplot(data = USALIFE, mapping = aes(x = State, colour = LE)) +
geom_freqpoly(binwidth = 0.1)
ggplot(data = USALIFE, mapping = aes(x = State, colour = LE)) +
geom_freqpoly(binwidth = 0.1)
library(tidyverse)
library(readxl)
world_population <- read_excel("C:/Users/mcdaw/Downloads/world_population.xlsx")
View(world_population)
ggplot(data = world_population, mapping = aes(x = "2022 Population", colour = Country)) +
geom_freqpoly(binwidth = 0.1)
ggplot(world_population) +
geom_bar(mapping = aes(x = "World Population Percentage"))
ggplot(world_population) +
geom_histogram(mapping = aes(x = "World Population Percentage", y = Country))
ggplot(world_population) +
geom_point(mapping = aes(x = "World Population Percentage", y = Country))
library(readxl)
Airports <- read_excel("C:/Users/mcdaw/Downloads/Airports.xlsx")
View(Airports)
ggplot(Airports) +
geom_point(mapping = aes(x = Country, y = Passengers))
ggplot(Airports) +
geom_smooth(mapping = aes(x = Country, y = Passengers))
ggplot(Airports) +
geom_boxplot(mapping = aes(x = Country, y = Passengers))
geom_freqpoly(mapping = aes(binwidth = 500)
geom_freqpoly(mapping = aes(binwidth = 500)
geom_freqpoly(mapping = aes
ggplot(data = Airports, mapping = aes(x = Country, y = Passengers)) +
ggplot(data = Airports) +
geom_freqpoly(mapping = aes,(x = Country, y = Passengers))
ggplot(data = Airports) +
geom_bar(mapping = aes,(x = Country, y = Passengers))
ggplot(data = Airports) +
geom_bar(mapping = aes,(x = Country,y = Passengers))
ggplot(data = Airports) +
geom_bar(mapping = aes,(x = Country))
ggplot(data = Airports) +
geom_bar(mapping = aes(x = Country, y = Passengers))
ggplot(data = Airports) +
geom_freqpoly(mapping = aes(x = Country, y = Passengers))
library(tidyverse)
ggplot(data = Airports) +
geom_smooth(mapping = aes(x = Country, y = Passengers))
ggplot(data = Airports) +
geom_histogram(mapping = aes(x = Country, y = Passengers))
ggplot(data = Airports) +
geom_histogram(mapping = aes(x = Country))
ggplot(data = Airports) +
geom_histogram(mapping = aes(x = Country))
ggplot(data = Airports) +
geom_histogram(mapping = aes(x = location))
library(readxl)
VideoGames <- read_excel("C:/Users/mcdaw/Downloads/VideoGames.xlsx")
View(VideoGames)
library(tidyverse)
ggplot(VideoGames) +
geom_boxplot(mapping = aes(x = Publisher, y = Critic_Score))
ggplot(VideoGames) +
geom_boxplot(mapping = aes(x = Publisher, y = Critic_Score))
ggplot(VideoGames) +
geom_point(mapping = aes(x = Publisher, y = Critic_Score))
ggplot(VideoGames) +
geom_point(mapping = aes(x = Global_Sales, y = Critic_Score))
ggplot(VideoGames) +
geom_point(mapping = aes(x = Platform, y = Critic_Score))
ggplot(VideoGames) +
geom_boxplot(mapping = aes(x = Platform, y = Critic_Score))
ggplot(VideoGames) +
geom_smooth(mapping = aes(x = Platform, y = Critic_Score))
ggplot(VideoGames) +
geom_histogram(mapping = aes(x = Platform, y = Critic_Score))
ggplot(VideoGames) +
geom_point(mapping = aes(x = Platform, y = Critic_Score))
ggplot(VideoGames) +
geom_point(mapping = aes(x = Genre, y = Critic_Score))
ggplot(VideoGames) +
geom_line(mapping = aes(x = Genre, y = Critic_Score))
ggplot(VideoGames) +
geom_polygon(mapping = aes(x = Genre, y = Critic_Score))
ggplot(VideoGames) +
geom_polygon(mapping = aes(x = Genre, y = Critic_Score))
ggplot(VideoGames) +
geom_freqpoly(mapping = aes(x = Genre, y = Critic_Score))
ggplot(VideoGames) +
geom_freqpoly(mapping = aes(x = Genre))
ggplot(VideoGames) +
geom_histogram(mapping = aes(x = Crit_Score, color = Genre))
ggplot(VideoGames) +
geom_histogram(mapping = aes(x = Critic_Score, color = Genre))
ggplot(VideoGames) +
geom_histogram(mapping = aes(x = Critic_Score, color = Genre))
ggplot(VideoGames) +
geom_histogram(mapping = aes(x = Critic_Score))
library(tidyverse)
library(tidyverse)
# tableau is a great visualization engine
# but R is a do-all workhorse
# watch how one line of code reshapes the data to make it more analyzeable
library(readxl)
library(tidyverse)
# write the data out again!
write_excel_csv(newdata,"ProblemCDataWide.csv")
# Spread the unique values for MSN from one Column into 605 columns,
# and fill in data
newdata <- pivot_wider(sesedsdata,names_from=MSN,values_from = Data)
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_xlsx("ProblemCData.xlsx")
# tableau is a great visualization engine
# but R is a do-all workhorse
# watch how one line of code reshapes the data to make it more analyzeable
library(readxl)
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_xlsx("ProblemCData.xlsx")
# Spread the unique values for MSN from one Column into 605 columns,
# and fill in data
newdata <- pivot_wider(sesedsdata,names_from=MSN,values_from = Data)
# write the data out again!
write_excel_csv(newdata,"ProblemCDataWide.csv")
# tableau is a great visualization engine
# but R is a do-all workhorse
# watch how one line of code reshapes the data to make it more analyzeable
library(readxl)
library(tidyverse)
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_xlsx("ProblemCData.xlsx")
# Spread the unique values for MSN from one Column into 605 columns,
# and fill in data
newdata <- pivot_wider(sesedsdata,names_from=MSN,values_from = Data)
# write the data out again!
write_excel_csv(newdata,"ProblemCDataWide.csv")
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_xlsx("ProblemCData.xlsx")
sesedsdata <- read_xlsx("ProblemCData.xlsx")
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_excel("ProblemCData.xlsx")
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_xlsx("ProblemCData.xlsx")
read_xlsx("ProblemCData.xlsx")
read_xlsx("ProblemCData.xlsx")
# tableau is a great visualization engine
# but R is a do-all workhorse
# watch how one line of code reshapes the data to make it more analyzeable
library(readxl)
library(readxl)
# tableau is a great visualization engine
# but R is a do-all workhorse
# watch how one line of code reshapes the data to make it more analyzeable
library(readxl)
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_xlsx("ProblemCData.xlsx")
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_xlsx("ProblemCData.xlsx")
# tableau is a great visualization engine
# but R is a do-all workhorse
# watch how one line of code reshapes the data to make it more analyzeable
library(readxl)
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_xlsx("ProblemCData.xlsx")
library(readxl)
dataset <- read_excel(NULL)
library(readxl)
ProblemCData <- read_excel("C:/Users/mcdaw/Downloads/ProblemCData.xlsx")
View(ProblemCData)
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_xlsx("ProblemCData.xlsx")
# Spread the unique values for MSN from one Column into 605 columns,
# and fill in data
newdata <- pivot_wider(sesedsdata,names_from=MSN,values_from = Data)
sesedsdata
sesedsdata
library(readxl)
library(readxl)
library(readxl)
library(readxl)
library(readxl)
library(readxl)
library(readxl)
sesedsdata <- read_xlsx("ProblemCData.xlsx")
sesedsdata <- read_xlsx("ProblemCData.xlsx")
library(tidyverse)
library(readxl)
library(tidyverse)
View(ProblemCData)
source("~/R Scripts/ProblemCdata.R")
source("~/R Scripts/ProblemCdata.R")
library(readxl)
library(tidyverse)
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_xlsx("C:\Users\mcdaw\Downloads\ProblemCData.xlsx")
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_xlsx("C:\\Users\\mcdaw\\Downloads\\ProblemCData.xlsx")
View(sesedsdata)
# Spread the unique values for MSN from one Column into 605 columns,
# and fill in data
newdata <- pivot_wider(sesedsdata,names_from=MSN,values_from = Data)
View(sesedsdata)
# Spread the unique values for MSN from one Column into 605 columns,
# and fill in data
newdata <- pivot_wider(sesedsdata,names_from=MSN,values_from = Data)
# write the data out again!
write_excel_csv(newdata,"ProblemCDataWide.csv")
View(sesedsdata)
View(sesedsdata)
# Spread the unique values for MSN from one Column into 605 columns,
# and fill in data
newdata <- pivot_wider(sesedsdata,names_from=MSN,values_from = Data)
library(readxl)
ProblemCData <- read_excel("C:/Users/mcdaw/Downloads/ProblemCData.xlsx")
View(ProblemCData)
# Spread the unique values for MSN from one Column into 605 columns,
# and fill in data
newdata <- pivot_wider(sesedsdata,names_from=MSN,values_from = Data)
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_xlsx("C:\\Users\\mcdaw\\Downloads\\ProblemCData.xlsx")
# Spread the unique values for MSN from one Column into 605 columns,
# and fill in data
newdata <- pivot_wider(sesedsdata,names_from=MSN,values_from = Data)
# write the data out again!
write_excel_csv(newdata,"ProblemCDataWide.csv")
View(sesedsdata)
View(ProblemCData)
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_xlsx("C:\\Users\\mcdaw\\Downloads\\ProblemCData.xlsx")
# tableau is a great visualization engine
# but R is a do-all workhorse
# watch how one line of code reshapes the data to make it more analyzable
library(readxl)
library(tidyverse)
# Grab Original Data Set (from first worksheet)
sesedsdata <- read_xlsx("C:\\Users\\mcdaw\\Downloads\\ProblemCData.xlsx")
# Spread the unique values for MSN from one Column into 605 columns,
# and fill in data
newdata <- pivot_wider(sesedsdata,names_from=MSN,values_from = Data)
# write the data out again!
write_excel_csv(newdata,"ProblemCDataWide.csv")
View(sesedsdata)
library(readr)
ProblemCDataWide <- read_csv("ProblemCDataWide.csv")
View(ProblemCDataWide)
install.packages("rtweet")
library(rtweet)
auth_setup_default()
AstroTweets <- get_timeline("@astros", n=2000)
PhilliesTweets <- get_timeline("@phillies", n=2000)
df <- rbind(AstroTweets, PhilliesTweets)
library(tidyverse)
write_csv(df, "WorldSeriesTweets.csv")
df %>%
ts_plot("1 day") +
ggplot2::theme_minimal() +
ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) +
ggplot2::labs(
x = NULL, y = NULL,
title = "Frequency of Astro and Phillies Tweets within the last 6 Months",
subtitle = "Twitter status (tweet) counts aggregated using one-day intervals",
caption = "\nSource: Data collected from Twitter's REST API via rtweet"
)
install.packages("tm")
library(tm)
alldataDF <- read.csv("WorldSeriesTweets.csv")
#Phillies wordcloud
philliesdf <- PhilliesTweets
review_source <-VectorSource(philliesdf$text)
corpus <- Corpus(review_source)
corpus <- tm_map( corpus, toSpace, "(f|ht)tp(s?)(.*)[.][a-z]+")
#both teams wordcloud
alldataDF <- df
review_source <-VectorSource(alldataDF$text)
corpus <- Corpus(review_source)
getTransformations()
toSpace = content_transformer( function(x, pattern) gsub(pattern," ",x) )
corpus <- tm_map( corpus, toSpace, "(f|ht)tp(s?)(.*)[.][a-z]+")
corpus <-tm_map(corpus, removePunctuation)
corpus <-tm_map(corpus, content_transformer(tolower))
corpus <-tm_map(corpus, stripWhitespace)
corpus <-tm_map(corpus, removeWords, stopwords("english"))
dtm <- DocumentTermMatrix(corpus)
inspect(removeSparseTerms(dtm,0.4))
dtm2 <- as.matrix(dtm)
frequency <- colSums(dtm2)
frequency <- sort(frequency, decreasing=TRUE)
frequency[1:20]
findFreqTerms(dtm,lowfreq = 10)
findAssocs(dtm,'phillies',corlimit=.2)
findAssocs(dtm,'final',corlimit=.2)
install.packages("wordcloud")
library(wordcloud)
words <- names(frequency)
wordcloud(words[1:50],frequency[1:50],colors=brewer.pal(8,"Dark2"))
#astros wordcloud
astrosdf <- AstroTweets
review_source <-VectorSource(astrosdf$text)
corpus <- Corpus(review_source)
corpus <- tm_map( corpus, toSpace, "(f|ht)tp(s?)(.*)[.][a-z]+")
corpus <-tm_map(corpus, removePunctuation)
corpus <-tm_map(corpus, content_transformer(tolower))
corpus <-tm_map(corpus, stripWhitespace)
corpus <-tm_map(corpus, removeWords, stopwords("english"))
dtm <- DocumentTermMatrix(corpus)
inspect(removeSparseTerms(dtm,0.4))
dtm2 <- as.matrix(dtm)
frequency <- colSums(dtm2)
frequency <- sort(frequency, decreasing=TRUE)
frequency[1:20]
findFreqTerms(dtm,lowfreq = 10)
findAssocs(dtm,'astros',corlimit=.2)
words <- names(frequency)
wordcloud(words[1:50],frequency[1:50],colors=brewer.pal(8,"Dark2"))
#Phillies wordcloud
philliesdf <- PhilliesTweets
review_source <-VectorSource(philliesdf$text)
corpus <- Corpus(review_source)
corpus <- tm_map( corpus, toSpace, "(f|ht)tp(s?)(.*)[.][a-z]+")
corpus <-tm_map(corpus, removePunctuation)
corpus <-tm_map(corpus, content_transformer(tolower))
corpus <-tm_map(corpus, stripWhitespace)
corpus <-tm_map(corpus, removeWords, stopwords("english"))
dtm <- DocumentTermMatrix(corpus)
inspect(removeSparseTerms(dtm,0.4))
dtm2 <- as.matrix(dtm)
frequency <- colSums(dtm2)
frequency <- sort(frequency, decreasing=TRUE)
frequency[1:20]
findFreqTerms(dtm,lowfreq = 10)
findAssocs(dtm,'phillies',corlimit=.2)
words <- names(frequency)
wordcloud(words[1:50],frequency[1:50],colors=brewer.pal(8,"Dark2"))
getTransformations()
library(syuzhet)
df$sentiment <- get_sentiment(df$text,method="syuzhet")
plot(df$sentiment)
write_csv(df,"tweetsandsentiments.csv")
#different types of sentiment graphs
ggplot(data=df) +
geom_histogram(mapping=aes(x=sentiment,fill=possibly_sensitive))
df$sentimentafinn <- get_sentiment(df$text,method="afinn")
ggplot(data=df) +
geom_histogram(mapping=aes(x=sentimentafinn))
df$sentimentafinn <- get_sentiment(df$text,method="afinn")
ggplot(data=df) +
geom_histogram(mapping=aes(x=sentimentafinn))
df$sentimentnrc <- get_sentiment(df$text,method="nrc")
ggplot(data=df) +
geom_histogram(mapping=aes(x=sentimentnrc))
nrc_data <- get_nrc_sentiment(df$text)
ggplot(data=df) +
geom_histogram(mapping=aes(x=sentimentnrc))
#astros wordcloud
astrosdf <- AstroTweets
review_source <-VectorSource(astrosdf$text)
corpus <- Corpus(review_source)
corpus <- tm_map( corpus, toSpace, "(f|ht)tp(s?)(.*)[.][a-z]+")
corpus <-tm_map(corpus, removePunctuation)
corpus <-tm_map(corpus, content_transformer(tolower))
corpus <-tm_map(corpus, stripWhitespace)
corpus <-tm_map(corpus, removeWords, stopwords("english"))
dtm <- DocumentTermMatrix(corpus)
inspect(removeSparseTerms(dtm,0.4))
dtm2 <- as.matrix(dtm)
frequency <- colSums(dtm2)
frequency <- sort(frequency, decreasing=TRUE)
frequency[1:20]
findFreqTerms(dtm,lowfreq = 10)
findAssocs(dtm,'astros',corlimit=.2)
words <- names(frequency)
wordcloud(words[1:50],frequency[1:50],colors=brewer.pal(8,"Dark2"))
#Phillies wordcloud
philliesdf <- PhilliesTweets
review_source <-VectorSource(philliesdf$text)
corpus <- Corpus(review_source)
corpus <- tm_map( corpus, toSpace, "(f|ht)tp(s?)(.*)[.][a-z]+")
corpus <-tm_map(corpus, removePunctuation)
corpus <-tm_map(corpus, content_transformer(tolower))
corpus <-tm_map(corpus, stripWhitespace)
corpus <-tm_map(corpus, removeWords, stopwords("english"))
dtm <- DocumentTermMatrix(corpus)
inspect(removeSparseTerms(dtm,0.4))
dtm2 <- as.matrix(dtm)
frequency <- colSums(dtm2)
frequency <- sort(frequency, decreasing=TRUE)
frequency[1:20]
findFreqTerms(dtm,lowfreq = 10)
findAssocs(dtm,'phillies',corlimit=.2)
words <- names(frequency)
wordcloud(words[1:50],frequency[1:50],colors=brewer.pal(8,"Dark2"))
findAssocs(dtm,'ringthebell',corlimit=.2)
findAssocs(dtm,'ringthebell',corlimit=.1)
findAssocs(dtm,'final',corlimit=.2)
findAssocs(dtm,'game',corlimit=.1)
findAssocs(dtm,'ringthebell',corlimit=.1)
findAssocs(dtm,'ringthebell',corlimit=.2)
findAssocs(dtm,'astros',corlimit=.2)
findAssocs(dtm,'astros',corlimit=.1)
findAssocs(dtm,'astros',corlimit=.01)
findAssocs(dtm,'phillies',corlimit=.01)
findAssocs(dtm,'phillies',corlimit=.2)
findAssocs(dtm,'phillies',corlimit=.3)
findAssocs(dtm,'astros',corlimit=.3)
findAssocs(dtm,'astros',corlimit=.1)
# Function to fetch game data
fetch_game_data <- function(player_id) {
game_data_url <- paste0("https://example.com/api/games/", player_id, "/last_10")
response <- GET(game_data_url)
if (http_status(response)$status == 200) {
return(content(response, as = "parsed"))
} else {
print("Failed to fetch game data.")
return(NULL)
}
}
getwd()
getwd()
myfunction <- function() (
x <- rnorm(100)
mean(x)
)
ln()
ln()
myfunction <- function() (
x <- rnorm(100)
mean(x)
)
myfunction <- function() (
X <- rnorm(100)
mean(X)
)
myfunction <- function() {
x <- rnorm(100)
mean(x)
}
ln()
ls()
myfunction()
save.image("C:\\Users\\mcdaw\\OneDrive\\Desktop\\R Coursea\\mycode.r")
dir()
source("mycode.r")
source("mycode.r")
souce("mycode.R")
source("mycode.r")
q()
